{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11117058,"sourceType":"datasetVersion","datasetId":6931878}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hiding Images in Plain Sight: Deep Steganography  Compatible with TensorFlow 2.17 \n\n#### An Unofficial Tensorflow Implementation","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:23:27.602889Z","iopub.execute_input":"2025-04-02T18:23:27.603303Z","iopub.status.idle":"2025-04-02T18:24:06.022223Z","shell.execute_reply.started":"2025-04-02T18:23:27.603274Z","shell.execute_reply":"2025-04-02T18:24:06.020947Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"%pylab inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.217563Z","iopub.status.idle":"2025-04-02T18:18:57.217948Z","shell.execute_reply":"2025-04-02T18:18:57.217771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:40:51.374243Z","iopub.execute_input":"2025-04-02T18:40:51.374664Z","iopub.status.idle":"2025-04-02T18:40:55.570698Z","shell.execute_reply.started":"2025-04-02T18:40:51.374617Z","shell.execute_reply":"2025-04-02T18:40:55.569552Z"}},"outputs":[{"name":"stdout","text":"2.19.0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import glob\nimport os\nfrom PIL import Image,ImageOps\nimport random\nimport tensorflow as tf\nimport time\nfrom datetime import datetime\nfrom os.path import join","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:40:55.572929Z","iopub.execute_input":"2025-04-02T18:40:55.573611Z","iopub.status.idle":"2025-04-02T18:40:55.578740Z","shell.execute_reply.started":"2025-04-02T18:40:55.573577Z","shell.execute_reply":"2025-04-02T18:40:55.577410Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Configuration\nAll Configuration related information is represented in CAPS","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = '/kaggle/input/steganography-imagenet/steganography_dataset_imagenet/train'\nTRAIN_PATH_COVER='/kaggle/input/steganography-imagenet/steganography_dataset_imagenet/train/cover'\nTRAIN_PATH_SECRET='/kaggle/input/steganography-imagenet/steganography_dataset_imagenet/train/secret'\nLOGS_Path = \"/kaggle/working/logs\"\nCHECKPOINTS_PATH = '/kaggle/working/checkpoints'\n\n\nBATCH_SIZE = 8\nLEARNING_RATE = .0001\nBETA = .75\n\nEXP_NAME = f\"beta_{BETA}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:50.306885Z","iopub.execute_input":"2025-04-02T19:06:50.307402Z","iopub.status.idle":"2025-04-02T19:06:50.312835Z","shell.execute_reply.started":"2025-04-02T19:06:50.307369Z","shell.execute_reply":"2025-04-02T19:06:50.311644Z"}},"outputs":[],"execution_count":88},{"cell_type":"markdown","source":"## Helper Methods to Handle images \nThe images are first converted to float values between 0 and 1. \n\nThen they are normalised using the Mean and STD from ImageNet. \n\nTo convert these normalised values back to images, a helper function to undo this normalisation is also written.","metadata":{}},{"cell_type":"code","source":"files_list_cover = glob.glob(join(TRAIN_PATH_COVER,\"**/*\"))\nfiles_list_secret= glob.glob(join(TRAIN_PATH_SECRET,\"**/*\"))\n\nfiles_list_cover=os.listdir(TRAIN_PATH_COVER)[:500]\nfiles_list_secret=os.listdir(TRAIN_PATH_SECRET)[:500]\n\n\n#for using images stored in subdirectories in a folder\nfiles_list_cover = glob.glob(join(TRAIN_PATH_COVER, \"**\", \"*\"), recursive=True)[:500]  # Recursive\nfiles_list_secret = glob.glob(join(TRAIN_PATH_SECRET, \"**\", \"*\"), recursive=True)[:500] \n\ndef normalize_batch(imgs):\n    return (imgs -  np.array([0.485, 0.456, 0.406])) /np.array([0.229, 0.224, 0.225])\n                                                        \ndef denormalize_batch(imgs,should_clip=True):\n    imgs= (imgs * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n    \n    if should_clip:\n        imgs= np.clip(imgs,0,1)\n    return imgs\n\ndef get_img_batch(files_list_cover,files_list_secret,batch_size=32,size=(224,224),should_normalise=True):\n   \n    batch_cover = []\n    batch_secret = []\n\n    for i in range(batch_size):\n        img_secret_path = random.choice(files_list_secret[:500])\n        img_cover_path = random.choice(files_list_cover[:500])\n        \n        img_secret = Image.open(img_secret_path).convert(\"RGB\")\n        img_cover = Image.open(img_cover_path).convert(\"RGB\")\n\n        img_secret = np.array(ImageOps.fit(img_secret,size),dtype=np.float32)\n        img_cover = np.array(ImageOps.fit(img_cover,size),dtype=np.float32)\n        \n        img_secret /= 255.\n        img_cover /= 255.\n        \n        batch_cover.append(img_cover)\n        batch_secret.append(img_secret)\n        \n    batch_cover,batch_secret = np.array(batch_cover) , np.array(batch_secret)\n    \n    if should_normalise:\n        batch_cover = normalize_batch(batch_cover)\n        batch_secret = normalize_batch(batch_secret)\n\n    return batch_cover,batch_secret\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:15:39.669320Z","iopub.execute_input":"2025-04-02T19:15:39.669717Z","iopub.status.idle":"2025-04-02T19:16:05.642525Z","shell.execute_reply.started":"2025-04-02T19:15:39.669689Z","shell.execute_reply":"2025-04-02T19:16:05.641522Z"}},"outputs":[],"execution_count":103},{"cell_type":"markdown","source":"## Network Definitions\nThe three networks are identical in terms of structure. \n\n1. The Prepare network takes in the **Secret Image** and outputs a (BATCH_SIZE,INPUT_HEIGHT,INPUT_WEIGHT,150) tensor. \n\n2. The Cover network takes in the output from 1. , and a *Cover Image*. It concatenates these two tensors , giving a (BATCH_SIZE,INPUT_HEIGHT,INPUT_WEIGHT,153) tensor. Then it performs Convolutions , and outputs a (BATCH_SIZE,INPUT_HEIGHT,INPUT_WEIGHT,3) image.\n\n3. The Reveal Network Takes in the output image from Cover Network , and outputs the Revealed Image (which is supposed to look like the **Secret Image**\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef get_prep_network_op(secret_tensor):\n    \n    with tf.compat.v1.variable_scope('prep_net'):\n        \n        with tf.compat.v1.variable_scope(\"3x3_conv_branch\"):\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation=tf.nn.relu, name=\"1\")(secret_tensor)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation=tf.nn.relu, name=\"2\")(conv_3x3)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation=tf.nn.relu, name=\"3\")(conv_3x3)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation=tf.nn.relu, name=\"4\")(conv_3x3)\n            \n        with tf.compat.v1.variable_scope(\"4x4_conv_branch\"):\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation=tf.nn.relu, name=\"1\")(secret_tensor)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation=tf.nn.relu, name=\"2\")(conv_4x4)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation=tf.nn.relu, name=\"3\")(conv_4x4)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation=tf.nn.relu, name=\"4\")(conv_4x4)\n\n        with tf.compat.v1.variable_scope(\"5x5_conv_branch\"):\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation=tf.nn.relu, name=\"1\")(secret_tensor)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation=tf.nn.relu, name=\"2\")(conv_5x5)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation=tf.nn.relu, name=\"3\")(conv_5x5)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation=tf.nn.relu, name=\"4\")(conv_5x5)\n            \n        concat_1 = tf.keras.layers.Concatenate(axis=3, name='concat_1')([conv_3x3, conv_4x4, conv_5x5])\n        \n        conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation=tf.nn.relu, name=\"final_5x5\")(concat_1)\n        conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation=tf.nn.relu, name=\"final_4x4\")(concat_1)\n        conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation=tf.nn.relu, name=\"final_3x3\")(concat_1)\n        \n        concat_final = tf.keras.layers.Concatenate(axis=3, name='concat_final')([conv_5x5, conv_4x4, conv_3x3])\n\n        return concat_final\n\n\n    \nimport tensorflow as tf\n\ndef get_hiding_network_op(cover_tensor, prep_output):\n    with tf.compat.v1.variable_scope('hide_net'):\n        concat_input = tf.concat([cover_tensor, prep_output], axis=3, name='images_features_concat')\n\n        with tf.compat.v1.variable_scope(\"3x3_conv_branch\"):\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"1\")(concat_input)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"2\")(conv_3x3)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"3\")(conv_3x3)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"4\")(conv_3x3)\n\n        with tf.compat.v1.variable_scope(\"4x4_conv_branch\"):\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"1\")(concat_input)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"2\")(conv_4x4)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"3\")(conv_4x4)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"4\")(conv_4x4)\n\n        with tf.compat.v1.variable_scope(\"5x5_conv_branch\"):\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"1\")(concat_input)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"2\")(conv_5x5)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"3\")(conv_5x5)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"4\")(conv_5x5)\n\n        concat_1 = tf.concat([conv_3x3, conv_4x4, conv_5x5], axis=3, name='concat_1')\n\n        conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"final_5x5\")(concat_1)\n        conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"final_4x4\")(concat_1)\n        conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"final_3x3\")(concat_1)\n\n        concat_final = tf.concat([conv_5x5, conv_4x4, conv_3x3], axis=3, name='concat_final')\n        output = tf.keras.layers.Conv2D(filters=3, kernel_size=1, padding='same', name='output')(concat_final)\n\n        return output\n\n        \n        \nimport tensorflow as tf\n\ndef get_reveal_network_op(container_tensor):\n    with tf.compat.v1.variable_scope('reveal_net'):\n        \n        with tf.compat.v1.variable_scope(\"3x3_conv_branch\"):\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"1\")(container_tensor)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"2\")(conv_3x3)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"3\")(conv_3x3)\n            conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"4\")(conv_3x3)\n        \n        with tf.compat.v1.variable_scope(\"4x4_conv_branch\"):\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"1\")(container_tensor)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"2\")(conv_4x4)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"3\")(conv_4x4)\n            conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"4\")(conv_4x4)\n\n        with tf.compat.v1.variable_scope(\"5x5_conv_branch\"):\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"1\")(container_tensor)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"2\")(conv_5x5)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"3\")(conv_5x5)\n            conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"4\")(conv_5x5)\n\n        concat_1 = tf.concat([conv_3x3, conv_4x4, conv_5x5], axis=3, name='concat_1')\n\n        conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu', name=\"final_5x5\")(concat_1)\n        conv_4x4 = tf.keras.layers.Conv2D(filters=50, kernel_size=4, padding='same', activation='relu', name=\"final_4x4\")(concat_1)\n        conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', activation='relu', name=\"final_3x3\")(concat_1)\n\n        concat_final = tf.concat([conv_5x5, conv_4x4, conv_3x3], axis=3, name='concat_final')\n\n        output = tf.keras.layers.Conv2D(filters=3, kernel_size=1, padding='same', name='output')(concat_final)\n\n    return output\n\n\ndef get_noise_layer_op(tensor,std=.1):\n    with tf.compat.v1.variable_scope(\"noise_layer\"):\n        return tensor + tf.random.normal(shape=tf.shape(tensor), mean=0.0, stddev=std, dtype=tf.float32) \n    \ndef get_loss_op(secret_true,secret_pred,cover_true,cover_pred,beta=.5):\n    with tf.compat.v1.variable_scope(\"losses\"):\n        beta = tf.constant(beta,name=\"beta\")\n        secret_mse = tf.keras.losses.MeanSquaredError()(secret_true, secret_pred)\n        cover_mse = tf.keras.losses.MeanSquaredError()(cover_true, cover_pred)\n        final_loss = cover_mse + beta*secret_mse\n        return final_loss , secret_mse , cover_mse \n\ndef get_tensor_to_img_op(tensor):\n    with tf.compat.v1.variable_scope(\"\",reuse=True):\n        t = tensor*tf.convert_to_tensor([0.229, 0.224, 0.225]) + tf.convert_to_tensor([0.485, 0.456, 0.406])\n        return tf.clip_by_value(t,0,1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:29:34.269613Z","iopub.execute_input":"2025-04-02T19:29:34.270197Z","iopub.status.idle":"2025-04-02T19:29:34.303659Z","shell.execute_reply.started":"2025-04-02T19:29:34.270156Z","shell.execute_reply":"2025-04-02T19:29:34.302433Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()  # Disable eager execution (needed for TensorFlow 1.x compatibility)\n\ndef prepare_training_graph(secret_tensor,cover_tensor,global_step_tensor):\n\n    prep_output_op = get_prep_network_op(secret_tensor)\n    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor,prep_output=prep_output_op)\n    noise_add_op = get_noise_layer_op(hiding_output_op)\n    reveal_output_op = get_reveal_network_op(noise_add_op)\n    \n    loss_op,secret_loss_op,cover_loss_op = get_loss_op(secret_tensor,reveal_output_op,cover_tensor,hiding_output_op,beta=BETA)\n\n    minimize_op = tf.compat.v1.train.AdamOptimizer(LEARNING_RATE).minimize(loss_op,global_step=global_step_tensor)\n    \n    tf.compat.v1.summary.scalar('loss', loss_op)\n    tf.compat.v1.summary.scalar('reveal_net_loss', secret_loss_op)\n    tf.compat.v1.summary.scalar('cover_net_loss', cover_loss_op)\n\n    tf.compat.v1.summary.image('secret',get_tensor_to_img_op(secret_tensor),max_outputs=1)\n    tf.compat.v1.summary.image('cover',get_tensor_to_img_op(cover_tensor),max_outputs=1)\n    tf.compat.v1.summary.image('hidden',get_tensor_to_img_op(hiding_output_op),max_outputs=1)\n    tf.compat.v1.summary.image('hidden_noisy',get_tensor_to_img_op(noise_add_op),max_outputs=1)\n    tf.compat.v1.summary.image('revealed',get_tensor_to_img_op(reveal_output_op),max_outputs=1)\n\n    merged_summary_op = tf.compat.v1.summary.merge_all()\n    \n    return minimize_op, merged_summary_op ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:54:17.532635Z","iopub.execute_input":"2025-04-02T19:54:17.533167Z","iopub.status.idle":"2025-04-02T19:54:17.542524Z","shell.execute_reply.started":"2025-04-02T19:54:17.533125Z","shell.execute_reply":"2025-04-02T19:54:17.541279Z"}},"outputs":[],"execution_count":187},{"cell_type":"code","source":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()  # Disable eager execution (needed for TensorFlow 1.x compatibility)\n\ndef prepare_test_graph(secret_tensor, cover_tensor):\n    with tf.compat.v1.variable_scope(\"\", reuse=tf.compat.v1.AUTO_REUSE):\n        prep_output_op = get_prep_network_op(secret_tensor)\n        hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor, prep_output=prep_output_op)\n        reveal_output_op = get_reveal_network_op(hiding_output_op)\n\n        loss_op, secret_loss_op, cover_loss_op = get_loss_op(secret_tensor, reveal_output_op, cover_tensor, hiding_output_op)\n\n        tf.compat.v1.summary.scalar('loss', loss_op)\n        tf.compat.v1.summary.scalar('reveal_net_loss', secret_loss_op)\n        tf.compat.v1.summary.scalar('cover_net_loss', cover_loss_op)\n\n\n        tf.compat.v1.summary.image('secret', get_tensor_to_img_op(secret_tensor), max_outputs=1)\n        tf.compat.v1.summary.image('cover', get_tensor_to_img_op(cover_tensor), max_outputs=1)\n        tf.compat.v1.summary.image('hidden', get_tensor_to_img_op(hiding_output_op), max_outputs=1)\n        tf.compat.v1.summary.image('revealed', get_tensor_to_img_op(reveal_output_op), max_outputs=1)\n\n        merged_summary_op = tf.compat.v1.summary.merge_all()\n\n        return merged_summary_op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:59:17.828456Z","iopub.execute_input":"2025-04-02T19:59:17.829054Z","iopub.status.idle":"2025-04-02T19:59:17.839020Z","shell.execute_reply.started":"2025-04-02T19:59:17.829018Z","shell.execute_reply":"2025-04-02T19:59:17.837700Z"}},"outputs":[],"execution_count":191},{"cell_type":"code","source":"def prepare_deployment_graph(secret_tensor,cover_tensor,covered_tensor):\n    with tf.compat.v1.variable_scope(\"\",reuse=True):\n\n        prep_output_op = get_prep_network_op(secret_tensor)\n        hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor,prep_output=prep_output_op)\n\n        reveal_output_op = get_reveal_network_op(covered_tensor)\n\n        return hiding_output_op ,  reveal_output_op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:25:30.117448Z","iopub.execute_input":"2025-04-02T19:25:30.117831Z","iopub.status.idle":"2025-04-02T19:25:30.123250Z","shell.execute_reply.started":"2025-04-02T19:25:30.117799Z","shell.execute_reply":"2025-04-02T19:25:30.122183Z"}},"outputs":[],"execution_count":133},{"cell_type":"code","source":"import tensorflow as tf\n\n# Enable TensorFlow 1.x compatibility mode\ntf.compat.v1.disable_eager_execution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:25:31.413528Z","iopub.execute_input":"2025-04-02T19:25:31.413892Z","iopub.status.idle":"2025-04-02T19:25:31.418648Z","shell.execute_reply.started":"2025-04-02T19:25:31.413863Z","shell.execute_reply":"2025-04-02T19:25:31.417524Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"import tensorflow as tf\n\n# Explicitly enable eager execution (which is the default in TF 2.x)\ntf.compat.v1.disable_eager_execution()\ntf.compat.v1.reset_default_graph()\n\n# Use tf.compat.v1.Session() instead\nsess = tf.compat.v1.Session(graph=tf.Graph())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:47:47.025026Z","iopub.execute_input":"2025-04-02T19:47:47.025460Z","iopub.status.idle":"2025-04-02T19:47:47.031400Z","shell.execute_reply.started":"2025-04-02T19:47:47.025429Z","shell.execute_reply":"2025-04-02T19:47:47.030058Z"}},"outputs":[],"execution_count":174},{"cell_type":"code","source":"#sess = tf.InteractiveSession(graph=tf.Graph())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:47:35.316667Z","iopub.execute_input":"2025-04-02T19:47:35.317084Z","iopub.status.idle":"2025-04-02T19:47:35.321537Z","shell.execute_reply.started":"2025-04-02T19:47:35.317049Z","shell.execute_reply":"2025-04-02T19:47:35.320459Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"import tensorflow as tf\n\n# Disable eager execution (required for placeholder-based execution)\ntf.compat.v1.disable_eager_execution()\n\n# Define placeholders using TensorFlow 1.x compatibility mode\nsecret_tensor = tf.compat.v1.placeholder(shape=[None, 224, 224, 3], dtype=tf.float32, name=\"input_prep\")\ncover_tensor = tf.compat.v1.placeholder(shape=[None, 224, 224, 3], dtype=tf.float32, name=\"input_hide\")\nglobal_step_tensor = tf.compat.v1.Variable(0, trainable=False, name='global_step')\n\n# Ensure that all other TensorFlow 1.x functions use tf.compat.v1\nwriter = tf.compat.v1.summary.FileWriter(join(LOGS_Path, EXP_NAME))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:47:50.190569Z","iopub.execute_input":"2025-04-02T19:47:50.190931Z","iopub.status.idle":"2025-04-02T19:47:50.204740Z","shell.execute_reply.started":"2025-04-02T19:47:50.190903Z","shell.execute_reply":"2025-04-02T19:47:50.203133Z"}},"outputs":[],"execution_count":175},{"cell_type":"code","source":"\ntest_op = prepare_test_graph(secret_tensor,cover_tensor)\n\ncovered_tensor = tf.compat.v1.placeholder(shape=[None,224,224,3],dtype=tf.float32,name=\"deploy_covered\")\ndeploy_hide_image_op , deploy_reveal_image_op = prepare_deployment_graph(secret_tensor,cover_tensor,covered_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:59:25.957214Z","iopub.execute_input":"2025-04-02T19:59:25.957616Z","iopub.status.idle":"2025-04-02T19:59:27.964309Z","shell.execute_reply.started":"2025-04-02T19:59:25.957585Z","shell.execute_reply":"2025-04-02T19:59:27.963217Z"}},"outputs":[],"execution_count":192},{"cell_type":"code","source":"train_op , summary_op = prepare_training_graph(secret_tensor,cover_tensor,global_step_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:59:28.445995Z","iopub.execute_input":"2025-04-02T19:59:28.446383Z","iopub.status.idle":"2025-04-02T19:59:31.388701Z","shell.execute_reply.started":"2025-04-02T19:59:28.446355Z","shell.execute_reply":"2025-04-02T19:59:31.387556Z"}},"outputs":[],"execution_count":193},{"cell_type":"code","source":"#saver = tf.compat.v1.train.Saver(max_to_keep=1)\n#sess.run(tf.compat.v1.global_variables_initializer())\n# saver.restore(sess,join(CHECKPOINTS_PATH,EXP_NAME))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:47:57.312498Z","iopub.execute_input":"2025-04-02T19:47:57.312849Z","iopub.status.idle":"2025-04-02T19:47:57.317206Z","shell.execute_reply.started":"2025-04-02T19:47:57.312821Z","shell.execute_reply":"2025-04-02T19:47:57.315882Z"}},"outputs":[],"execution_count":178},{"cell_type":"code","source":"total_steps = len(files_list_cover)//BATCH_SIZE + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:47:57.718505Z","iopub.execute_input":"2025-04-02T19:47:57.718927Z","iopub.status.idle":"2025-04-02T19:47:57.723509Z","shell.execute_reply.started":"2025-04-02T19:47:57.718894Z","shell.execute_reply":"2025-04-02T19:47:57.722322Z"}},"outputs":[],"execution_count":179},{"cell_type":"code","source":"from tqdm import tqdm\n\nwith tf.compat.v1.Session() as sess:\n    sess.run(tf.compat.v1.global_variables_initializer())  # Ensure variables are initialized\n\n    for ep in range(100):\n\n        with tqdm(range(total_steps), desc=f\"Epoch {ep+1}/100\", unit=\"step\") as pbar:\n          for step in pbar:  # Use tqdm progress bar\n\n            covers,secrets = get_img_batch(files_list_cover=files_list_cover, files_list_secret=files_list_secret,batch_size=BATCH_SIZE)\n            print(f\"cover shape is {covers.shape} and secret shape is {secrets.shape}\")\n            sess.run([train_op],feed_dict={\"input_prep:0\":secrets,\"input_hide:0\":covers})\n            \n            if step % 10 ==0 :\n                \n                summary,global_step = sess.run([summary_op,global_step_tensor],feed_dict={\"input_prep:0\":secrets,\"input_hide:0\":covers})\n                writer.add_summary(summary,global_step)\n                \n            if step % 100 ==0 :\n                \n                covers,secrets = get_img_batch(files_list_cover=files_list_cover, files_list_secret=files_list_secret,batch_size=1)\n                summary,global_step = sess.run([test_op,global_step_tensor],feed_dict={\"input_prep:0\":secrets,\"input_hide:0\":covers})\n                writer.add_summary(summary,global_step)\n    \n        \n        save_path = saver.save(sess, join(CHECKPOINTS_PATH,EXP_NAME+\".chkp\"),global_step=global_step)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:59:32.092877Z","iopub.execute_input":"2025-04-02T19:59:32.093271Z","iopub.status.idle":"2025-04-02T20:10:05.016875Z","shell.execute_reply.started":"2025-04-02T19:59:32.093242Z","shell.execute_reply":"2025-04-02T20:10:05.014692Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/100:   0%|          | 0/63 [00:00<?, ?step/s]","output_type":"stream"},{"name":"stdout","text":"cover shape is (8, 224, 224, 3) and secret shape is (8, 224, 224, 3)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100:   2%|▏         | 1/63 [03:38<3:45:23, 218.12s/step]","output_type":"stream"},{"name":"stdout","text":"cover shape is (8, 224, 224, 3) and secret shape is (8, 224, 224, 3)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100:   3%|▎         | 2/63 [05:21<2:33:01, 150.52s/step]","output_type":"stream"},{"name":"stdout","text":"cover shape is (8, 224, 224, 3) and secret shape is (8, 224, 224, 3)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100:   5%|▍         | 3/63 [07:03<2:08:33, 128.55s/step]","output_type":"stream"},{"name":"stdout","text":"cover shape is (8, 224, 224, 3) and secret shape is (8, 224, 224, 3)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100:   6%|▋         | 4/63 [08:45<1:56:10, 118.15s/step]","output_type":"stream"},{"name":"stdout","text":"cover shape is (8, 224, 224, 3) and secret shape is (8, 224, 224, 3)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100:   6%|▋         | 4/63 [10:28<2:34:28, 157.10s/step]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-194-61ce269b500a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mcovers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecrets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_list_cover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_list_cover\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_list_secret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_list_secret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cover shape is {covers.shape} and secret shape is {secrets.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input_prep:0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msecrets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"input_hide:0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcovers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    978\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    979\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1221\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1401\u001b[0m                            run_metadata)\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1405\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1388\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1391\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1481\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1482\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1483\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1484\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                                             run_metadata)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":194},{"cell_type":"code","source":"# sess.close()\n\nwriter.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.242643Z","iopub.status.idle":"2025-04-02T18:18:57.242907Z","shell.execute_reply":"2025-04-02T18:18:57.242795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"covers,secrets = get_img_batch(files_list_cover=files_list_cover,files_list_secret=files_list_secret,batch_size=1)\n\ncover = covers.squeeze()\nsecret = secrets.squeeze()\n# Plot and save the cover image\nplt.figure()\nplt.imshow(denormalize_batch(cover))\nplt.title(\"Cover\")\nplt.savefig(\"cover.png\")   # Saves the figure to cover.png\nplt.show()\n\n# Plot and save the secret image\nplt.figure()\nplt.imshow(denormalize_batch(secret))\nplt.title(\"Secret\")\nplt.savefig(\"secret.png\")  # Saves the figure to secret.png\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T20:10:05.017797Z","iopub.status.idle":"2025-04-02T20:10:05.018232Z","shell.execute_reply":"2025-04-02T20:10:05.018025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run the model to get the hidden image\nhidden = sess.run(deploy_hide_image_op, feed_dict={'input_prep:0': secrets, 'input_hide:0': covers})\n\nplt.figure()\nplt.imshow(denormalize_batch(hidden.squeeze()))\nplt.title(\"Hidden\")\nplt.savefig(\"hidden.png\")\nplt.show()\n\n# Run the model to get the revealed image\nrevealed = sess.run(deploy_reveal_image_op, feed_dict={'deploy_covered:0': hidden})\n\nplt.figure()\nplt.imshow(denormalize_batch(revealed.squeeze()))\nplt.title(\"Revealed\")\nplt.savefig(\"revealed.png\")\nplt.show()\n\n# Optionally, save the output of hiding network if available:\nplt.figure()\nplt.imshow(np.clip(hiding_output.squeeze(), 0, 1))\nplt.title(\"Hiding Output\")\nplt.savefig(\"hiding_output.png\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T20:10:05.019311Z","iopub.status.idle":"2025-04-02T20:10:05.019702Z","shell.execute_reply":"2025-04-02T20:10:05.019514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hidden = sess.run(deploy_hide_image_op,feed_dict={'input_prep:0':secrets,'input_hide:0':covers})\n\nplt.imshow(denormalize_batch(hidden.squeeze()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.244566Z","iopub.status.idle":"2025-04-02T18:18:57.244836Z","shell.execute_reply":"2025-04-02T18:18:57.244723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"revealed = sess.run(deploy_reveal_image_op,feed_dict={'deploy_covered:0':hidden})\n\nplt.imshow(denormalize_batch(revealed.squeeze()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.245737Z","iopub.status.idle":"2025-04-02T18:18:57.246135Z","shell.execute_reply":"2025-04-02T18:18:57.245983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(np.clip(hiding_output.squeeze(),0,1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.247020Z","iopub.status.idle":"2025-04-02T18:18:57.247330Z","shell.execute_reply":"2025-04-02T18:18:57.247210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hiding_network_output = sess.run([hiding_output_op],\n                                  feed_dict={secret_tensor:secrets,cover_tensor:covers})[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.248052Z","iopub.status.idle":"2025-04-02T18:18:57.248412Z","shell.execute_reply":"2025-04-02T18:18:57.248275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.imshow(np.clip(hiding_network_output[0],0,1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.249215Z","iopub.status.idle":"2025-04-02T18:18:57.249600Z","shell.execute_reply":"2025-04-02T18:18:57.249415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# join(\"OK\",\".OK\",\".OK\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.250404Z","iopub.status.idle":"2025-04-02T18:18:57.250673Z","shell.execute_reply":"2025-04-02T18:18:57.250561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# covers,secrets = get_img_batch(files_list=files_list,batch_size=BATCH_SIZE)\n\n# type(secrets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.251535Z","iopub.status.idle":"2025-04-02T18:18:57.252000Z","shell.execute_reply":"2025-04-02T18:18:57.251814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# files_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.252747Z","iopub.status.idle":"2025-04-02T18:18:57.253189Z","shell.execute_reply":"2025-04-02T18:18:57.252979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# image_str = tf.placeholder(tf.string)\n# im_tf = tf.image.decode_image(image_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.253792Z","iopub.status.idle":"2025-04-02T18:18:57.254080Z","shell.execute_reply":"2025-04-02T18:18:57.253960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cover_imgs = []\n# hidden_imgs = []\n# hidden_noisy = []\n# reveal_imgs = []\n# secret_imgs = []\n\n\n# count = 0\n# for e in tf.train.summary_iterator(join(LOGS_Path,'beta_0.25','events.out.tfevents.1516061354.pcvirus')):\n#     for v in e.summary.value:\n#         if v.tag == 'train/train/cover/image':\n#             output = im_tf.eval(feed_dict={image_str:v.image.encoded_image_string})\n#             cover_imgs.append(output)\n            \n#         if v.tag == 'train/train/hidden/image':\n#             output = im_tf.eval(feed_dict={image_str:v.image.encoded_image_string})\n#             hidden_imgs.append(output)\n        \n#         if v.tag == 'train/train/hidden_noisy/image':\n#             output = im_tf.eval(feed_dict={image_str:v.image.encoded_image_string})\n#             hidden_noisy.append(output)\n            \n#         if v.tag == 'train/train/revealed/image':\n#             output = im_tf.eval(feed_dict={image_str:v.image.encoded_image_string})\n#             reveal_imgs.append(output)\n            \n#         if v.tag == 'train/train/secret/image':\n#             output = im_tf.eval(feed_dict={image_str:v.image.encoded_image_string})\n#             secret_imgs.append(output)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T18:18:57.254848Z","iopub.status.idle":"2025-04-02T18:18:57.255162Z","shell.execute_reply":"2025-04-02T18:18:57.255006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}